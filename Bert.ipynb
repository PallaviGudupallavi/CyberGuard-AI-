{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1EHS1CpCgBdQ1O4j5Va609Ele-0NjcDKX","authorship_tag":"ABX9TyPNQudq89PYKhXqQldXgIqj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Install required libraries\n","!pip install transformers datasets torch scikit-learn\n","\n","# Import necessary libraries\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n","import pandas as pd\n","import numpy as np\n","import re\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Load the dataset\n","train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CyberguarAI-Hackathon/train.csv')\n","\n","# Preprocess text\n","train_df['sub_category'].fillna('Unknown', inplace=True)\n","train_df.dropna(subset=['crimeaditionalinfo'], inplace=True)\n","\n","# Check the number of instances per class\n","class_counts = train_df['sub_category'].value_counts()\n","print(\"Class counts:\\n\", class_counts)\n","\n","# Filter out classes with fewer than 2 samples\n","valid_classes = class_counts[class_counts > 1].index\n","train_df_filtered = train_df[train_df['sub_category'].isin(valid_classes)]\n","\n","# Optional: Combine small classes into an 'Other' category\n","# train_df_filtered['sub_category'] = train_df_filtered['sub_category'].apply(lambda x: x if class_counts[x] > 1 else 'Other')\n","\n","# Define text cleaning function\n","def clean_text(text):\n","    text = text.lower()\n","    text = re.sub(r'[^\\w\\s]', ' ', text)\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text\n","\n","train_df_filtered['cleaned_info'] = train_df_filtered['crimeaditionalinfo'].apply(clean_text)\n","\n","# Split the dataset into training and validation sets (stratified to preserve class proportions)\n","X_train, X_val, y_train, y_val = train_test_split(\n","    train_df_filtered['cleaned_info'],\n","    train_df_filtered['sub_category'],\n","    test_size=0.2,\n","    stratify=train_df_filtered['sub_category'],  # Stratify to preserve class proportions\n","    random_state=42\n",")\n","\n","# Load BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Encode the text\n","max_length = 128  # Adjust max length as needed\n","\n","def encode_data(texts, tokenizer, max_length):\n","    return tokenizer(\n","        list(texts),\n","        max_length=max_length,\n","        truncation=True,\n","        padding='max_length',\n","        return_tensors=\"pt\"\n","    )\n","\n","train_encodings = encode_data(X_train, tokenizer, max_length)\n","val_encodings = encode_data(X_val, tokenizer, max_length)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = torch.tensor(label_encoder.fit_transform(y_train))\n","y_val_encoded = torch.tensor(label_encoder.transform(y_val))\n","\n","# Create a custom dataset class\n","class CyberDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.encodings['input_ids'][idx],\n","            'attention_mask': self.encodings['attention_mask'][idx],\n","            'labels': self.labels[idx]\n","        }\n","\n","train_dataset = CyberDataset(train_encodings, y_train_encoded)\n","val_dataset = CyberDataset(val_encodings, y_val_encoded)\n","\n","# Load the BERT model for classification\n","model = BertForSequenceClassification.from_pretrained(\n","    'bert-base-uncased',\n","    num_labels=len(label_encoder.classes_)\n",")\n","\n","# Define optimizer and loss function\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","# Move model to GPU if available\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)\n","\n","# DataLoader for batching\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=16)\n","\n","# Training loop\n","epochs = 3\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","    for batch in train_loader:\n","        optimizer.zero_grad()\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f\"Epoch {epoch + 1}: Loss = {total_loss / len(train_loader)}\")\n","\n","# Validation\n","model.eval()\n","predictions = []\n","true_labels = []\n","with torch.no_grad():\n","    for batch in val_loader:\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n","        true_labels.extend(labels.cpu().numpy())\n","\n","# Classification report\n","print(classification_report(true_labels, predictions, target_names=label_encoder.classes_))\n","\n","# Compute confusion matrix\n","cm = confusion_matrix(true_labels, predictions)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(12, 10))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","# Plot precision, recall, and F1-score for each class\n","metrics = precision_recall_fscore_support(true_labels, predictions, zero_division=1)\n","precision, recall, f1_score = metrics[:3]\n","classes = label_encoder.classes_\n","\n","x = np.arange(len(classes))\n","width = 0.2\n","\n","plt.figure(figsize=(15, 7))\n","plt.bar(x - width, precision, width, label='Precision', color='skyblue')\n","plt.bar(x, recall, width, label='Recall', color='orange')\n","plt.bar(x + width, f1_score, width, label='F1-Score', color='green')\n","\n","plt.xticks(x, classes, rotation=90)\n","plt.xlabel('Classes')\n","plt.ylabel('Metrics')\n","plt.title('Precision, Recall, and F1-Score by Class')\n","plt.legend(loc='upper right')\n","plt.tight_layout()\n","plt.show()\n","\n","# Plot class distribution in the dataset\n","class_counts = np.bincount(true_labels)\n","plt.figure(figsize=(12, 6))\n","plt.bar(classes, class_counts, color='purple')\n","plt.xticks(rotation=90)\n","plt.xlabel('Classes')\n","plt.ylabel('Number of Instances')\n","plt.title('Class Distribution in Dataset')\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kcsIc4LLWZN2","outputId":"ce0ed493-0166-4e78-d277-e0b619028c65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-3-59781855371f>:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  train_df['sub_category'].fillna('Unknown', inplace=True)\n"]},{"output_type":"stream","name":"stdout","text":["Class counts:\n"," sub_category\n","UPI Related Frauds                                                      26843\n","Other                                                                   10877\n","DebitCredit Card FraudSim Swap Fraud                                    10802\n","Internet Banking Related Fraud                                           8871\n","Unknown                                                                  6591\n","Fraud CallVishing                                                        5802\n","Cyber Bullying  Stalking  Sexting                                        4089\n","EWallet Related Fraud                                                    4047\n","FakeImpersonating Profile                                                2299\n","Profile Hacking Identity Theft                                           2072\n","Cheating by Impersonation                                                1987\n","Unauthorised AccessData Breach                                           1114\n","Online Job Fraud                                                          912\n","DematDepository Fraud                                                     761\n","Tampering with computer source documents                                  567\n","Hacking/Defacement                                                        540\n","Ransomware Attack                                                         534\n","Malware Attack                                                            521\n","SQL Injection                                                             508\n","Denial of Service (DoS)/Distributed Denial of Service (DDOS) attacks      504\n","Data Breach/Theft                                                         484\n","Cryptocurrency Fraud                                                      480\n","Online Gambling  Betting                                                  444\n","Provocative Speech for unlawful acts                                      417\n","Email Hacking                                                             349\n","Business Email CompromiseEmail Takeover                                   290\n","Online Trafficking                                                        183\n","Cyber Terrorism                                                           161\n","EMail Phishing                                                            157\n","Online Matrimonial Fraud                                                  132\n","Damage to computer computer systems etc                                   108\n","Website DefacementHacking                                                  89\n","Ransomware                                                                 56\n","Impersonating Email                                                        44\n","Intimidating Email                                                         29\n","Against Interest of sovereignty or integrity of India                       1\n","Name: count, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-3-59781855371f>:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  train_df_filtered['cleaned_info'] = train_df_filtered['crimeaditionalinfo'].apply(clean_text)\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]}]}